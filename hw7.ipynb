{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning homework7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Import librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Read data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_x = np.loadtxt('data/mnist_X.csv', delimiter=',')\n",
    "mnist_y = np.loadtxt('data/mnist_label.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Different dimension reduction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_reduce(x, y, method, need_y=False, title=''):\n",
    "    \"\"\"Use specific method to reduce dimension to 2 and plot result.\"\"\"\n",
    "    x_reduce = method(x, y, reduce_to=2) if need_y else method(x, reduce_to=2)\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.suptitle(title)\n",
    "    ax.scatter(x_reduce[:, 0], x_reduce[:, 1], c=y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(x, reduce_to=2):\n",
    "    \"\"\"Perform PCA on dataset x, reduce to a certain dimension.\"\"\"\n",
    "    # Compute convariance matrix\n",
    "    x_cov = np.cov(x, rowvar=False)\n",
    "    # Compute eigen value and eigen vector of convariance\n",
    "    eigen_val, eigen_vec = np.linalg.eig(x_cov)\n",
    "    # Sort eigen value and vector according to eigen value in descending order\n",
    "    eigen_vec = eigen_vec[:, np.argsort(eigen_val)[::-1]]\n",
    "    eigen_val = eigen_val[np.argsort(eigen_val)[::-1]]\n",
    "    # Project original data to new space\n",
    "    result = x @ eigen_vec[:, :reduce_to]\n",
    "    return result.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_reduce(mnist_x, mnist_y, pca, title='PCA without standardization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    \"\"\"Standardize x, resulting in zero mean and unit variance.\"\"\"\n",
    "    z = np.zeros_like(x)\n",
    "    std_x = x.std(axis=0)\n",
    "    std_x_gt0 = std_x > 0\n",
    "    z[:, std_x_gt0] = (x - x.mean(axis=0))[:, std_x_gt0] / std_x[std_x_gt0]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_reduce(standardize(mnist_x), mnist_y, pca, title='PCA with standardization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 LDA (Linear Discriminant Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "- https://sebastianraschka.com/Articles/2014_python_lda.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda(x, y, reduce_to=2):\n",
    "    \"\"\"Perform LDA on dataset x, reduce to a certain dimension.\"\"\"\n",
    "    labels = np.unique(y)\n",
    "    n_dim = x.shape[1]\n",
    "    s_w = np.zeros((n_dim, n_dim))\n",
    "    s_b = np.zeros_like(s_w)\n",
    "    total_mean = x.mean(axis=0)\n",
    "    for label in labels:\n",
    "        mean = x[y==label].mean(axis=0)\n",
    "        # Compute within-class scatter matrix\n",
    "        s_w += np.cov(x[y==label], rowvar=False)\n",
    "        # Compute between-class scatter matrix\n",
    "        to_total_mean = mean - total_mean\n",
    "        s_b += (to_total_mean[None, :] * to_total_mean[:, None]) * (y==label).sum()\n",
    "    # Get eigen value and eigen vector from (s_w)^-1 * s_b\n",
    "    eigen_val, eigen_vec = np.linalg.eig(np.linalg.pinv(s_w) @ s_b)\n",
    "    # Sort eigen value and vector according to eigen value in descending order\n",
    "    eigen_vec = eigen_vec[:, np.argsort(eigen_val)[::-1]]\n",
    "    eigen_val = eigen_val[np.argsort(eigen_val)[::-1]]\n",
    "    # Project original data to new space\n",
    "    result = x @ eigen_vec[:, :reduce_to]\n",
    "    return result.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_reduce(mnist_x, mnist_y, lda, need_y=True, title='LDA without standardization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_reduce(standardize(mnist_x), mnist_y, lda, need_y=True, title='LDA with standardization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Symmetric SNE and T-SNE (Stochastic Neighbor Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Eigen face"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
